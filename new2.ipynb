{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.preprocessing import MultiLabelBinarizer, StandardScaler, LabelEncoder\n",
    "import pyodbc\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "server = '172.16.68.4'\n",
    "database = 'ELCM_QADB'\n",
    "username = 'Temp'\n",
    "password = 'Temp@123'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn_str = f'DRIVER={{SQL Server}};SERVER={server};DATABASE={database};UID={username};PWD={password}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    conn = pyodbc.connect(conn_str)\n",
    "    print(\"Connected\")\n",
    "except pyodbc.Error as e:\n",
    "    print(\"Error connecting to the database:\", e)\n",
    "    # Handle the error accordingly, such as logging, retrying, or exiting the program\n",
    "    exit()\n",
    "\n",
    "cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vishal\\AppData\\Local\\Temp\\ipykernel_21640\\3824703933.py:4: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql_query(query, conn)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Fetching data from the database\n",
    "    query = 'EXEC [ED].[GetALLEmployeeMLData]'\n",
    "    df = pd.read_sql_query(query, conn)\n",
    "except pd.errors.DatabaseError as e:\n",
    "    print(\"Database Error:\", e)\n",
    "    # Handle the error accordingly, such as reconnecting or exiting the program\n",
    "    exit()\n",
    "except pd.errors.EmptyDataError:\n",
    "    print(\"The query returned an empty dataframe. Check your SQL query.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Handling duplicates\n",
    "    mentors_df = df[df['IsMentor'] == 1].drop_duplicates(subset='EmpID')\n",
    "except KeyError:\n",
    "    print(\"Column 'IsMentor' or 'EmpID' not found in the dataframe.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Preprocessing skills column\n",
    "    mentors_df['Skills'] = mentors_df['Skills'].str.split(', ')\n",
    "except KeyError:\n",
    "    print(\"Column 'Skills' not found in the dataframe.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Encoding Designation column\n",
    "    label = LabelEncoder()\n",
    "    mentors_df['Designation'] = label.fit_transform(mentors_df['Designation'])\n",
    "except KeyError:\n",
    "    print(\"Column 'Designation' not found in the dataframe.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Preprocessing skills data for MultiLabelBinarizer\n",
    "    mlb = MultiLabelBinarizer()\n",
    "    expanded_skill_data = mlb.fit_transform(mentors_df['Skills'])\n",
    "    expanded_skill_df = pd.DataFrame(expanded_skill_data, columns=mlb.classes_, index=mentors_df.index)\n",
    "except AttributeError:\n",
    "    print(\"Attribute 'Skills' not found in the dataframe.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Combining encoded skills with the DataFrame\n",
    "    mentors_df = mentors_df.drop('Skills', axis=1).join(expanded_skill_df)\n",
    "except KeyError:\n",
    "    print(\"Column 'Skills' not found in the dataframe.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Fitting Nearest Neighbors model\n",
    "    knn = NearestNeighbors(n_neighbors=5)\n",
    "    knn.fit(mentors_df.drop(['EmployeeNo', 'Name', 'IsMentor'], axis=1))\n",
    "except ValueError as e:\n",
    "    print(\"Value Error:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_mentors(employee_code, knn_model, mentors_df, mlb, label, n_recommendations=5):\n",
    "    try:\n",
    "        # Fetching mentee data from the database\n",
    "        mentee_query = f\"EXEC [ED].[GetEmployeeMLData] @Employeecode = {employee_code}\"\n",
    "        mentee_data = pd.read_sql_query(mentee_query, conn).iloc[:1]\n",
    "    except pd.errors.DatabaseError as e:\n",
    "        print(\"Database Error:\", e)\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        # Preprocessing mentee data\n",
    "        mentee_data['Skills'] = mentee_data['Skills'].str.split(', ')\n",
    "        mentee_skill_data = mlb.transform(mentee_data['Skills'])\n",
    "        mentee_skill_df = pd.DataFrame(mentee_skill_data, columns=mlb.classes_, index=mentee_data.index)\n",
    "        mentee_data['Designation'] = label.transform(mentee_data['Designation'])\n",
    "        mentee_data = mentee_data.drop('Skills', axis=1).join(mentee_skill_df)\n",
    "    except KeyError:\n",
    "        print(\"Column 'Skills' or 'Designation' not found in the mentee data.\")\n",
    "        # Handle the error accordingly\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        # Finding nearest neighbors\n",
    "        distances, indices = knn_model.kneighbors(mentee_data.drop(['EmployeeNo', 'Name', 'IsMentor'], axis=1), n_neighbors=n_recommendations)\n",
    "    except ValueError as e:\n",
    "        print(\"Value Error:\", e)\n",
    "        # Handle the error accordingly\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        # Fetching recommended mentors\n",
    "        recommended_mentors = mentors_df.iloc[indices[0]]\n",
    "        return recommended_mentors\n",
    "    except IndexError:\n",
    "        print(\"Index Error: Insufficient data to recommend mentors.\")\n",
    "        # Handle the error accordingly\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model and related objects\n",
    "with open('model.pkl', 'wb') as model_file:\n",
    "    pickle.dump(knn, model_file)\n",
    "\n",
    "with open('mlb.pkl', 'wb') as mlb_file:\n",
    "    pickle.dump(mlb, mlb_file)\n",
    "\n",
    "with open('label.pkl', 'wb') as label_file:\n",
    "    pickle.dump(label, label_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_objects():\n",
    "    with open('model.pkl', 'rb') as model_file:\n",
    "        knn_model = pickle.load(model_file)\n",
    "\n",
    "    with open('mlb.pkl', 'rb') as mlb_file:\n",
    "        mlb_object = pickle.load(mlb_file)\n",
    "\n",
    "    with open('label.pkl', 'rb') as label_file:\n",
    "        label_object = pickle.load(label_file)\n",
    "\n",
    "\n",
    "    return knn_model, mlb_object, label_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, jsonify, render_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [15/Feb/2024 12:47:52] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [15/Feb/2024 12:47:54] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [15/Feb/2024 12:47:54] \"GET /favicon.ico HTTP/1.1\" 404 -\n",
      "C:\\Users\\Vishal\\AppData\\Local\\Temp\\ipykernel_21640\\1328717824.py:5: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  mentee_data = pd.read_sql_query(mentee_query, conn).iloc[:1]\n",
      "127.0.0.1 - - [15/Feb/2024 12:47:57] \"POST /get_recommendations HTTP/1.1\" 200 -\n",
      "C:\\Users\\Vishal\\AppData\\Local\\Temp\\ipykernel_21640\\1328717824.py:5: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  mentee_data = pd.read_sql_query(mentee_query, conn).iloc[:1]\n",
      "127.0.0.1 - - [15/Feb/2024 12:48:07] \"POST /get_recommendations HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "app = Flask(__name__)\n",
    "@app.route('/')\n",
    "def home():\n",
    "    return render_template('index1.html')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "@app.route(\"/get_recommendations\", methods=[\"POST\"])\n",
    "def get_recommendations():\n",
    "    employeeCode = request.form.values()\n",
    "    knn_model, mlb_object, label_object = load_model_objects()\n",
    "    recommended_mentors = []\n",
    "    for code in employeeCode:\n",
    "        recommended_mentor = recommend_mentors(code, knn_model, mentors_df, mlb_object, label_object)\n",
    "        recommended_mentors.append(recommended_mentor.head().to_dict(orient='records'))\n",
    "    return jsonify(recommended_mentors)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(debug=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
